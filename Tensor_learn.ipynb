{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "#_是inplace的调用方式，会修改自己读书数据例如a_.add(b)会导致a的值改变\n",
    "#Tensor和numpy用法很像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.5783e-09, 3.1816e+12, 2.7096e-09],\n",
      "        [2.6409e-06, 1.0257e-08, 1.2823e+16]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([1, 3, 5, 7])\n",
      "tensor([ 1.0000,  5.5000, 10.0000])\n",
      "tensor([[ 0.1058,  0.0473,  0.0522],\n",
      "        [ 1.4934,  0.1200, -1.1571]])\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#Tensor的创建\n",
    "\n",
    "#a的值是随机值\n",
    "print(t.Tensor(2,3))\n",
    "\n",
    "#确定矩阵的值\n",
    "print(t.Tensor([[1,2,3],[4,5,6]]))\n",
    "\n",
    "#全1矩阵\n",
    "print(t.ones(2,3))\n",
    "\n",
    "#全0矩阵\n",
    "print(t.zeros(2,3))\n",
    "\n",
    "#步长生成\n",
    "print(t.arange(1,9,2))\n",
    "\n",
    "#线性平分\n",
    "print(t.linspace(1,10,3))\n",
    "\n",
    "#随机数列\n",
    "print(t.randn(2,3))\n",
    "\n",
    "#对角线为1\n",
    "print(t.eye(4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#将tensor转成lists\n",
    "b.tolist()\n",
    "#查看tenosr的尺寸\n",
    "print( b.size() )\n",
    "print( b.shape )\n",
    "print( b.numel() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "torch.Size([1, 2, 3])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#形状变换\n",
    "a=t.arange(0,6)\n",
    "b=t.Tensor([[1,2,3],[4,5,6]])\n",
    "print(a)\n",
    "\n",
    "#二维固定转换\n",
    "print(a.view(2,3))\n",
    "\n",
    "#单一固定\n",
    "print(a.view(-1,3))\n",
    "\n",
    "#把数组增加一个维度\n",
    "print(b.unsqueeze(0).size())\n",
    "print(b.squeeze(0).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.]])\n",
      "tensor([[1., 2., 3., 4.],\n",
      "        [5., 6., 1., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#resize()和view()不同，resize可以改变出比原来尺寸大或者小的矩阵\n",
    "#且变成更小的以后，原来的还是保存着的。\n",
    "print(b.resize_(1,3))\n",
    "print(b.resize_(3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置默认Tensor格式\n",
    "t.set_default_tensor_type('torch.FloatTensor')\n",
    "#还有ByteTensor\\Char\\Short\\Int型，转换成CUDA只需要 torch.cuda.类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#常见逐元素操作命令\n",
    "#abs/sqrt/div/exp/fmod取余/log/pow\n",
    "#cos/sin/asin/atan2/cosh\n",
    "#ceil上取整/round四舍五入/floor下取整/trunc取正数部分\n",
    "#clamp(input,min,max)超过min max截断\n",
    "#sigmod/tanh激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#常见的归并操作\n",
    "#mean/sum/median/mode众数\n",
    "#norm范数/dist距离\n",
    "#std标准差/var方差\n",
    "#cumsum累加/cumprob累乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#常见的线性代数函数\n",
    "#trace对角线之和\n",
    "#diag对角线元素\n",
    "#triu/tril矩阵的上三角/下三角\n",
    "#mm/bmm 矩阵乘法/batch的矩阵乘法\n",
    "#addmm/addbmm/addmv\n",
    "#t转制\n",
    "#dot/cross内积/外积\n",
    "#inverse求逆矩阵\n",
    "#svd奇异值分解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy-->Tensor 由此可借用numpy中的算法，开销很小\n",
    "import numpy as np\n",
    "a = np.ones([2,3])\n",
    "#trans by \n",
    "b=t.from_numpy(a)\n",
    "#or\n",
    "b=t.Tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#其他需要注意的地方\n",
    "#持久化\n",
    "if t.cuda.is_available():\n",
    "    a=a.cuda(1)\n",
    "    t.save(a,'a.pth')\n",
    "    \n",
    "    b=t.load('a.pth')\n",
    "#向量化！！！\n",
    "#如果直接使用c++风格的运算，比内建函数相差速度近10倍。因此尽量使用内建函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
